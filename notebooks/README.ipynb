{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "according-mining",
   "metadata": {},
   "source": [
    "# Training models\n",
    "\n",
    "\n",
    "### Trained models\n",
    "- text vectorization: Tf-Idf, Bag-of-words\n",
    "- classification: Multinomial/Complement NB\n",
    "\n",
    "### Model details\n",
    "\n",
    "##### Inputs\n",
    "\n",
    "\n",
    "A list (batch) of preprocessed and tokenized list of tokens as **List[List[str]]**\n",
    "example: \n",
    "\n",
    "    [['team', 'ah', 'vip', 'tool', 'free', 'key', 'for', 'everyone', 'global'],\n",
    "     ['sports', 'expert', 'to', 'help', 'you', 'high', 'investment',]]\n",
    "     \n",
    "##### Outputs\n",
    "\n",
    "**List[Dict[str, float]]**\n",
    "\n",
    "    [\n",
    "        {'Education': 0.5303325652226045, 'Foreign Languages': 0.23760836574825156, 'Travel & Tourism': 0.23205906902914397},\n",
    "        {'Education': 0.5303325652226045, 'Foreign Languages': 0.23760836574825156, 'Travel & Tourism': 0.23205906902914397},\n",
    "    ]\n",
    "\n",
    "\n",
    "##### Model files\n",
    "\n",
    "    models/trained/tgcat/en_tgcat.pt\n",
    "    models/trained/tgcat/ru_tgcat.pt\n",
    "    \n",
    "    \n",
    "##### Sample prediction\n",
    "\n",
    "    src/train/predict.py\n",
    "\n",
    "##### Test files\n",
    "\n",
    "    data/processed/en_predictions.json      \n",
    "    data/processed/ru_predictions.json\n",
    "    \n",
    "### Use models\n",
    "\n",
    "The vectorizer and the classifier saved as [TorchScript](https://pytorch.org/docs/stable/jit.html)\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "filepath = \"path/to/model.pt\"\n",
    "\n",
    "scripted_model = torch.jit.load(filepath)\n",
    "out = scripted_model(inputs)\n",
    "```\n",
    "\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Clean text: remove URLs, lowercase\n",
    "2. Tokenize: get tokens, filter out non-word and one-char tokens\n",
    "3. Join tokens: join title, description, recent_posts with '\\n'\n",
    "3. Vectorize texts to get word embeddings\n",
    "4. Classify to get probabilities of each topic\n",
    "5. Take top 2\n",
    "6. Normalize probabilities to sum up to one\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
